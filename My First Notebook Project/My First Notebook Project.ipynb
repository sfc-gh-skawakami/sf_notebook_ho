{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "gwzjhqfczz4o5z2qy7d4",
   "authorId": "4469144185903",
   "authorName": "SKAWAKAMI",
   "authorEmail": "shinichi.kawakami@snowflake.com",
   "sessionId": "e881364b-c8d2-4110-be7f-5e66252ff239",
   "lastEditTime": 1755236984430
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e886713-6ff9-4064-84d3-9c2480d3d3a9",
   "metadata": {
    "collapsed": false,
    "name": "intro_md"
   },
   "source": [
    "# :snowflake: Snowflake Notebooks へようこそ :notebook:\n",
    "\n",
    "[Snowflake Notebooks](https://docs.snowflake.com/LIMITEDACCESS/snowsight-notebooks/ui-snowsight-notebooks-about)でPythonとSQLをシームレスに活用して、データ分析を次のレベルに引き上げましょう！⚡️\n",
    "\n",
    "初めてのプロジェクトを始めるためのクイックノートブックです！🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100c4f5-3947-4d38-a399-a7848a1be6bf",
   "metadata": {
    "collapsed": false,
    "name": "packages_md"
   },
   "source": "## Pythonパッケージの追加 🎒\n\nノートブックには、numpy、pandas、matplotlibなど、データサイエンス🧪や機械学習🧠でよく使われるPythonライブラリが事前にインストールされています！\n\n他のパッケージを使用したい場合は、右上の`Packages`ドロップダウンをクリックして、ノートブックに追加のパッケージを追加してください。\n\nこのデモでは、ノートブック作成時にenvironment.ymlの一部として`matplotlib`と`scipy`パッケージを追加します。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d25856-380e-4e01-831c-47189920d1fa",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "packages"
   },
   "outputs": [],
   "source": [
    "# このノートブックで使用するPythonパッケージをインポート\n",
    "import streamlit as st\n",
    "import altair as alt\n",
    "\n",
    "# ノートブックに事前インストールされているライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 追加したパッケージ\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a24bb-0b18-4066-97af-7d81b58a45e9",
   "metadata": {
    "name": "with_local_script_md",
    "collapsed": false
   },
   "source": "## ローカルパッケージの追加\nノートブックにはファイルを追加する機能があり、pythonスクリプトを追加することも可能になっています。\n\nサイドバーで `ファイル` タブを開き、`+`アイコンをクリックするとファイルのアップロード・追加が行えます。\n\n> **注意**\n> ノートブックでPythonパッケージとして使用するファイルをアップロードする場合、Warehouse Runtimeで実行する際は\n> `.py`と `.zip` ファイルのみがサポートされている点にご注意ください。\n> Container Runtimeでは、.whl（wheel）ファイルもサポートされています。 `.zip` ファイルとしてパッケージをインポートする場合、\n> ルートディレクトリに `__init__.py `ファイルが存在し、それがPythonパッケージであることを示す必要があります。"
  },
  {
   "cell_type": "code",
   "id": "95912d33-5824-45c9-9454-6c0b11759a28",
   "metadata": {
    "language": "python",
    "name": "with_local_script"
   },
   "outputs": [],
   "source": "from getCustomerFakerData import gen_fake_customers\n\ndf_fake_customers = gen_fake_customers(100)\ndf_fake_customers",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "341fbd60-3e9b-48d0-84e4-5456b965d78b",
   "metadata": {
    "name": "private_package_md",
    "collapsed": false
   },
   "source": "## プライベートリポジトリからのインポート\n```\nコンテナランタイムでのみ使用可能\n```\nPipは、JFrog Artifactoryのようなプライベートソースからのパッケージのインストールを基本認証でサポートしています。ノートブックを外部アクセス統合（External Access Integration）用に設定し、リポジトリにアクセスできるようにします。\n\n1. ネットワークルールを作成し、アクセスしたいリポジトリを指定します。例えば、このネットワークルールはJFrogリポジトリを指定しています:\n```sql\nCREATE OR REPLACE NETWORK RULE jfrog_network_rule\n  MODE = EGRESS\n  TYPE = HOST_PORT\n  VALUE_LIST = ('<your-repo>.jfrog.io');\n```\n2. 外部ネットワーク位置への認証に必要な資格情報を表すシークレットを作成します。\n```sql\nCREATE OR REPLACE SECRET jfrog_token\n  TYPE = GENERIC_STRING\n  SECRET_STRING = '<your-jfrog-token>';\n```\n3. リポジトリへのアクセスを許可する外部アクセス統合を作成します：\n```sql\nCREATE OR REPLACE EXTERNAL ACCESS INTEGRATION jfrog_integration\n  ALLOWED_NETWORK_RULES = (jfrog_network_rule)\n  ALLOWED_AUTHENTICATION_SECRETS = (jfrog_token)\n  ENABLED = TRUE;\n\nGRANT USAGE ON INTEGRATION jfrog_integration TO ROLE data_scientist;\n```\n4. 外部アクセス統合とシークレットをノートブックに関連付けます。\n```sql\nALTER NOTEBOOK my_notebook\n  SET EXTERNAL_ACCESS_INTEGRATIONS = (jfrog_integration),\n    SECRETS = ('jfrog_token' = jfrog_token);\n```\n5. 外部アクセス設定にアクセスするには、ノートブックの右上にある「ワークシートのその他のアクション」（ノートブックアクションメニュー）を選択します。\n6. 「ノートブック設定」を選択し、次に「External Access」タブを選択します。\n7. リポジトリに接続する外部アクセス統合を選択します。\nノートブックが再起動します。\n8. ノートブックが再起動されたら、リポジトリからインストール可能になります\n```cmd\n!pip install hello-jfrog --index-url https://<user>:<token>@<your-repo>.jfrog.io/artifactory/api/pypi/test-pypi/simple\n```"
  },
  {
   "cell_type": "markdown",
   "id": "8ff8e747-4a94-4f91-a971-e0f86bdc073a",
   "metadata": {
    "collapsed": false,
    "name": "sql_querying_md"
   },
   "source": [
    "## 手軽なSQLクエリ 💡 \n",
    "\n",
    "同じワークシート内でPythonとSQLを簡単に切り替えることができます。\n",
    "\n",
    "サンプルデータを生成するSQLを書いてみましょう。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b8b95-674b-4191-a29d-2c850f27fd68",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "sql_querying"
   },
   "outputs": [],
   "source": [
    "-- スノーボード製品の合成データセットを価格と評価と共に生成\n",
    "SELECT CONCAT('SNOW-',UNIFORM(1000,9999, RANDOM())) AS PRODUCT_ID, \n",
    "       ABS(NORMAL(5, 3, RANDOM())) AS RATING, \n",
    "       ABS(NORMAL(750, 200::FLOAT, RANDOM())) AS PRICE\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 100));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cefaa-d16b-4eb7-8a7e-f297095351b1",
   "metadata": {
    "collapsed": false,
    "name": "cell_querying_python_md"
   },
   "source": [
    "## Pythonでの作業に戻る 🐍\n",
    "\n",
    "セルに名前を付けて、後続のセルでその出力を参照することができます。\n",
    "\n",
    "SQL結果にPythonから直接アクセスし、結果をpandas DataFrameに変換できます。🐼\n",
    "\n",
    "```python\n",
    "# SQLセルの出力をSnowpark DataFrameとしてアクセス\n",
    "my_snowpark_df = sql_querying.to_df()\n",
    "``` \n",
    "\n",
    "```python\n",
    "# SQLセルの出力をpandas DataFrameに変換\n",
    "my_df = sql_querying.to_pandas()\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2338253-c62a-4da1-b52b-569f23282689",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell_querying_python"
   },
   "outputs": [],
   "source": [
    "df = sql_querying.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319acb1-dc60-4087-94dd-6f661e8d532c",
   "metadata": {
    "collapsed": false,
    "name": "visualize_md"
   },
   "source": [
    "## 📊 データの可視化\n",
    "\n",
    "[Altair](https://altair-viz.github.io/)を使用して、データ分布をヒストグラムとして簡単に可視化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb2295-2bc6-41ce-b801-ed2dcc1162a0",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "visualize"
   },
   "outputs": [],
   "source": [
    "# Altairで結果をプロット\n",
    "chart = alt.Chart(df,title=\"評価分布\").mark_bar().encode(\n",
    "    alt.X(\"RATING\", bin=alt.Bin(step=2)),\n",
    "    y='count()',\n",
    ")\n",
    "\n",
    "st.altair_chart(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6cbb1-5488-445b-a81f-5caec127b519",
   "metadata": {
    "collapsed": false,
    "name": "plotting_md"
   },
   "source": [
    "チャートをカスタマイズして、カーネル密度推定（KDE）と中央値をプロットしたいとします。matplotlibを使用して価格分布をプロットできます。`.plot`コマンドは内部的に`scipy`を使用してKDEプロファイルを計算することに注意してください。これは、このチュートリアルの前半でパッケージとして追加したものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b78b8f-3de6-4863-9eec-d07c0e848d67",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "plotting"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,3))\n",
    "plt.tick_params(left = False, right = False , labelleft = False) \n",
    "\n",
    "price = df[\"PRICE\"]\n",
    "price.plot(kind = \"hist\", density = True, bins = 15)\n",
    "price.plot(kind=\"kde\", color='#c44e52')\n",
    "\n",
    "\n",
    "# パーセンタイルを計算\n",
    "median = price.median()\n",
    "ax.axvline(median,0, color='#dd8452', ls='--')\n",
    "ax.text(median,0.8, f'中央値: {median:.2f}  ',\n",
    "        ha='right', va='center', color='#dd8452', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# チャートを美しくする\n",
    "plt.style.use(\"bmh\")\n",
    "plt.title(\"価格分布\")\n",
    "plt.xlabel(\"価格 (ビン化)\")\n",
    "left, right = plt.xlim()   \n",
    "plt.xlim((0, right))  \n",
    "# 目盛りと軸線を削除\n",
    "ax.tick_params(left = False, bottom = False)\n",
    "for ax, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ab8c4-7725-44b0-bec8-72dc48bb7b89",
   "metadata": {
    "collapsed": false,
    "name": "snowpark_md"
   },
   "source": [
    "## Snowparkを使用したデータ操作 🛠️\n",
    "\n",
    "お気に入りのPythonデータサイエンスライブラリを使用することに加えて、[Snowpark API](https://docs.snowflake.com/en/developer-guide/snowpark/index)を使用してノートブック内でデータをスケールでクエリおよび処理することもできます。\n",
    "\n",
    "まず、アクティブなノートブックセッションを通じてsession変数を直接取得できます。session変数は、SnowflakeのPython APIを使用するためのアクセスポイントです。"
   ]
  },
  {
   "cell_type": "code",
   "id": "97390d6a-7ce4-4865-a7f7-8ea068f3f15e",
   "metadata": {
    "language": "python",
    "name": "snowpark_overview",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\n\nst.image(\"images/Snowpark.png\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f19769f-0c85-4731-854f-819c8ee8df72",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "Snowflakeの `QUERY_TAG` は、セッションレベルでオプションとして設定可能なパラメーターであり、ユーザーがセッション内で実行される任意のSQL文に文字列を関連付けることができます。このタグは、`QUERY_HISTORY` ビューおよびテーブル関数に記録され、クエリ活動の監視、監査、分析に役立つ重要なメカニズムを提供します。[クエリ履歴でクエリのアクティビティをモニターする](https://docs.snowflake.com/ja/user-guide/ui-snowsight-activity#review-query-history-in-snowsight)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "snowpark"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n# セッションにクエリタグを追加。デバッグとパフォーマンス監視に役立ちます。\nsession.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"notebook_demo_pack\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"is_quickstart\":0, \"source\":\"notebook\"}}"
  },
  {
   "cell_type": "markdown",
   "id": "0573e8eb-70fd-4a3a-b96e-07dc53a0c21b",
   "metadata": {
    "collapsed": false,
    "name": "snowpark2_md"
   },
   "source": [
    "例えば、Snowparkを使用してpandas DataFrameをSnowflakeのテーブルに保存することができます。💾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbc323-c2ec-44c9-a846-3f47c218af1e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "snowpark2"
   },
   "outputs": [],
   "source": [
    "session.write_pandas(df,\"SNOW_CATALOG\",auto_create_table=True, table_type=\"temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a58ea-eddd-456e-b94d-8d09ce330738",
   "metadata": {
    "collapsed": false,
    "name": "snowpark3_md"
   },
   "source": [
    "`SNOW_CATALOG`テーブルが作成されたので、以下の構文を使用してテーブルをロードできます：\n",
    "\n",
    "```python\n",
    "df = session.table(\"<DATABASE_NAME>.<SCHEMA_NAME>.<TABLE_NAME>\")\n",
    "```\n",
    "\n",
    "セッションがアクセスしたいテーブルのデータベースとスキーマに既に設定されている場合は、テーブル名を直接参照できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "snowpark3"
   },
   "outputs": [],
   "source": [
    "df = session.table(\"SNOW_CATALOG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5c4af-7432-400c-abc3-53d0ca098362",
   "metadata": {
    "collapsed": false,
    "name": "snowpark4_md"
   },
   "source": [
    "テーブルをロードしたら、Snowparkの[`describe`](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrame.describe)を呼び出して基本的な記述統計を計算できます。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636ed2e-5030-4661-99c8-96b086d25530",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "snowpark4"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff82704-9c54-4d59-b35c-974a2a55ba5a",
   "metadata": {
    "name": "pandas_on_snowflake_md",
    "collapsed": false
   },
   "source": "## Pandas on Snowflake\n\n[pandas on Snowflake](https://docs.snowflake.com/ja/developer-guide/snowpark/python/pandas-on-snowflake)は、開発者がSnowflake内のデータに対して直接pandasコードを実行できるようにします。ユーザーは、Snowflakeのパフォーマンス、スケーラビリティ、ガバナンスを活用しながら、慣れ親しんだpandasのネイティブ体験を同じように得ることができます。\n\nこのクイックスタートでは、Snowpark pandas API を使用して Snowflake で pandas を実行する方法を示します。また、Snowpark pandas API がネイティブの pandas API と非常に類似しており、従来の pandas パイプラインを数行のコード変更だけでスケールアップできることも確認できます。このノートブックは Snowflake Notebook で実行できます。\n\n### pandas on Snowflakeを使うべき時\n以下のいずれかに当てはまる場合は、pandas on Snowflakeを使用する必要があります。\n\n- あなたはpandas API と、より広い PyData エコシステムに精通しています。\n- pandasに精通し、同じコードベースで共同作業をしたい人とチームで仕事をします。\n- pandasで書かれた既存のコードがあります\n- あなたのワークフローには、pandas DataFrames でサポートされているように、注文に関連するニーズがあります。例えば、ワークフロー全体でデータセットが同じ順序で並んでいる必要があります\n- AI-ベースのコパイロット・ツールによる、より正確なコード補完を好みます。\n\n**注意**) 以下のサンプルコードは、Snowflake Marketplaceにある[Finance & Economics](https://app.snowflake.com/marketplace/listing/GZTSZAS2KF7/snowflake-public-data-products-finance-economics)にあるデータを参照しているものになります。実行するためには、`modin`をパッケージに追加する必要があります。"
  },
  {
   "cell_type": "code",
   "id": "76ff8f9e-c0e9-4d93-8ae0-045d0ecc82ca",
   "metadata": {
    "language": "python",
    "name": "pandas_on_snowflake0"
   },
   "outputs": [],
   "source": "import snowflake.snowpark.modin.plugin\nimport modin.pandas as md\nfrom time import perf_counter\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e161a861-4743-4ae3-8a48-b92fb9f26ff6",
   "metadata": {
    "language": "python",
    "name": "pandas_on_snowflake1"
   },
   "outputs": [],
   "source": "# padas on Snowflakeを利用した場合\nstart = perf_counter()\nspd_pf = md.read_snowflake(\"FINANCIAL__ECONOMIC_ESSENTIALS.CYBERSYN.STOCK_PRICE_TIMESERIES\")\nend = perf_counter()\ndata_size = len(spd_pf)\nprint(f\"Snowpark Pandasに {data_size}行のデータを読み込み。処理時間 {end - start} 秒\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3938c0c0-c57d-4a8c-b81d-9ffbf8eeb8d7",
   "metadata": {
    "language": "python",
    "name": "read_to_pandas"
   },
   "outputs": [],
   "source": "# Daraframe APIを利用して、Pandasにデータを格納した場合\nstart = perf_counter()\npd_pf = session.table(\"FINANCIAL__ECONOMIC_ESSENTIALS.CYBERSYN.STOCK_PRICE_TIMESERIES\").to_pandas()\nend = perf_counter()\ndata_size = len(pd_pf)\nprint(f\"pandasに {data_size}行のデータを読み込み。処理時間 {end - start} 秒\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d4ccea6-a7f6-4c3b-8dcc-920701efb2e7",
   "metadata": {
    "collapsed": false,
    "name": "variables_md"
   },
   "source": [
    "## SQLセル内でのPython変数の使用 🔖\n",
    "\n",
    "Jinja構文`{{..}}`を使用して、SQLクエリ内でPython変数を以下のように参照できます。\n",
    "\n",
    "```python\n",
    "threshold = 5\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- SQLでPython変数を参照\n",
    "SELECT * FROM SNOW_CATALOG where RATING > {{threshold}}\n",
    "```\n",
    "\n",
    "これを実践して、Pythonで設定した平均値と標準偏差の値に基づいて評価の値の分布を生成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb85963-53ea-46b6-be96-c164c397539a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "variables"
   },
   "outputs": [],
   "source": [
    "mean = 5 \n",
    "stdev = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64f767-a598-42d2-966a-a2414ad3ecb4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "variables2"
   },
   "outputs": [],
   "source": [
    "-- Python変数`mean`と`stdev`を使用してSQLクエリを構成する方法に注目\n",
    "-- Python変数がSQLクエリを動的に構成する方法に注目\n",
    "CREATE OR REPLACE TABLE SNOW_CATALOG AS \n",
    "SELECT CONCAT('SNOW-',UNIFORM(1000,9999, RANDOM())) AS PRODUCT_ID, \n",
    "       ABS(NORMAL({{mean}}, {{stdev}}, RANDOM())) AS RATING, \n",
    "       ABS(NORMAL(750, 200::FLOAT, RANDOM())) AS PRICE\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e59cc-3d51-41c9-bd8d-2f600e7c6b61",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "variables3"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM SNOW_CATALOG;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4ed30-1eca-469e-b970-27b06affb526",
   "metadata": {
    "collapsed": false,
    "name": "subqueries_md"
   },
   "source": [
    "### サブクエリゲームのレベルアップ! 🧑‍🎓\n",
    "\n",
    "PythonおよびSQLセルの結果参照にて学習したことと組み合わせることで、[CTEs](https://docs.snowflake.com/en/user-guide/queries-cte) で長いサブクエリを簡素化することができます。\n",
    "\n",
    "たとえば、5を超える評価を持つすべての製品の平均評価を計算したい場合。通常、次のようなものを書く必要があります:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab80f9-2903-410c-ac01-a08f9746c1e6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "subqueries"
   },
   "outputs": [],
   "source": [
    "WITH RatingsAboveFive AS (\n",
    "    SELECT RATING\n",
    "    FROM SNOW_CATALOG\n",
    "    WHERE RATING > 5\n",
    ")\n",
    "SELECT AVG(RATING) AS AVG_RATING_ABOVE_FIVE\n",
    "FROM RatingsAboveFive;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd954592-93ba-4919-a7d2-2659d63a87dc",
   "metadata": {
    "collapsed": false,
    "name": "subqueries2_md"
   },
   "source": [
    "Snowflake Notebooksを使用すると、クエリがずっと簡単になります！Jinjaを使って別のSQLセルからSQLテーブルを参照することで、同じ結果を得ることができます。例：`{{my_cell}}`。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828a1ef-2270-482e-81fc-d97c85823e43",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "subqueries2"
   },
   "outputs": [],
   "source": [
    "SELECT AVG(RATING) FROM {{variables3}}\n",
    "WHERE RATING > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d99691-578d-4df2-a1c1-cde4ee7e1cd0",
   "metadata": {
    "collapsed": false,
    "name": "streamlit_md"
   },
   "source": [
    "## Streamlitを利用したインタラクティブなアプリの作成🪄\n",
    "\n",
    "これらすべてをまとめて、異なるパラメータがデータ分布ヒストグラムの形状にどのような影響を与えるかを探索するStreamlitアプリを構築してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe67464-68f5-4bcf-a40d-684a58e3a44d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "streamlit"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.markdown(\"# スライダーを動かして調整し、結果の更新を見てみましょう！ 👇\")\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    mean = st.slider('評価分布の平均値',0,10,3) \n",
    "with col2:\n",
    "    stdev = st.slider('評価分布の標準偏差', 0, 10, 5)\n",
    "\n",
    "query =f'''CREATE OR REPLACE TABLE SNOW_CATALOG AS \n",
    "SELECT CONCAT('SNOW-',UNIFORM(1000,9999, RANDOM())) AS PRODUCT_ID, \n",
    "       ABS(NORMAL({mean}, {stdev}, RANDOM())) AS RATING, \n",
    "       ABS(NORMAL(750, 200::FLOAT, RANDOM())) AS PRICE\n",
    "FROM TABLE(GENERATOR(ROWCOUNT => 100));'''\n",
    "session.sql(query).collect()\n",
    "\n",
    "\n",
    "# Snowparkからテーブルを読み込み、結果をプロット\n",
    "df = session.table(\"SNOW_CATALOG\").to_pandas()\n",
    "# Altairで結果をプロット\n",
    "alt.Chart(df).mark_bar().encode(\n",
    "    alt.X(\"RATING\", bin=alt.Bin(step=2)),\n",
    "    y='count()',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cd696-cd03-4018-9be5-7d7dfaa730c1",
   "metadata": {
    "collapsed": false,
    "name": "shortcuts_md"
   },
   "source": [
    "## キーボードショートカットで高速実行 🏃\n",
    "\n",
    "これらのショートカットを使用すると、ノートブック内をより迅速にナビゲートできます。\n",
    "\n",
    "| コマンド | ショートカット |\n",
    "| --- | ----------- |\n",
    "| **このセルを実行して次に進む** | SHIFT + ENTER |\n",
    "| **このセルのみ実行** | CMD + ENTER |\n",
    "| **すべてのセルを実行** | CMD + SHIFT + ENTER |\n",
    "| **下にセルを追加** | b |\n",
    "| **上にセルを追加** | a |\n",
    "| **このセルを削除** | d+d |\n",
    "\n",
    "\\\n",
    "右下の`?`ボタンをクリックすると、ショートカットの完全なリストを表示できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e571490-2a0a-4bbc-9413-db5520d74cce",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "cleanup"
   },
   "outputs": [],
   "source": [
    "-- チュートリアル後に環境をクリーンアップするためのクリーンアップコード\n",
    "DROP TABLE SNOW_CATALOG;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230992ce-c36b-461d-af1d-ccb03486423c",
   "metadata": {
    "name": "working_with_file_md",
    "collapsed": false
   },
   "source": "# Snowflake Notebooksでファイルを扱う方法 🗄️\n\nこの例では、notebooksでファイルを扱う方法と、それらをstageに永続的に保存する方法を説明します。"
  },
  {
   "cell_type": "markdown",
   "id": "a08e255b-3351-4674-879e-3ae59cba8a9b",
   "metadata": {
    "name": "temp_file_md",
    "collapsed": false
   },
   "source": "## 一時ファイルの操作\n\nnotebookから書き込んだファイルは、notebookに関連付けられたlocal stageに一時的に保存されます。\n\n**notebookセッションを終了するとすぐに、これらのファイルにアクセスできなくなることに注意してください。**\n\n簡単なファイルを作成して、この仕組みの例を見てみましょう。"
  },
  {
   "cell_type": "code",
   "id": "bb9f748e-d45a-432e-a9a8-1070af7ddc89",
   "metadata": {
    "language": "python",
    "name": "temp_file_py1"
   },
   "outputs": [],
   "source": "import os\nos.mkdir(\"myfolder/\")\nos.chdir(\"myfolder/\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90017e96-2cd5-43a1-8c7c-078c10557744",
   "metadata": {
    "language": "python",
    "name": "temp_file_py2"
   },
   "outputs": [],
   "source": "with open(\"myfile.txt\",'w') as f:\n    f.write(\"abc\")\nf.close()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc96dec9-862b-4d22-a8fc-2e68d08ebd1e",
   "metadata": {
    "name": "temp_file_md2",
    "collapsed": false
   },
   "source": "stageにあるファイルを確認してみましょう。`notebook_app.ipynb`と`environment.yml`はSnowflake notebookの一部として自動的に作成されるファイルです。新しく作成したファイル`myfile.txt`が確認できます。"
  },
  {
   "cell_type": "code",
   "id": "305d8749-c064-4821-b2b5-0f488679555b",
   "metadata": {
    "language": "python",
    "name": "temp_file_py3"
   },
   "outputs": [],
   "source": "import os\nos.listdir()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "09f79195-3c47-4179-aad4-5aa460f37148",
   "metadata": {
    "name": "temp_file_md3",
    "collapsed": false
   },
   "source": "では、notebookをセッションから切断してみましょう。これは、ブラウザページを閉じる/更新するか、右上の`Active`ボタンをクリックして`End session`を押すことで行えます。\n\nこのセルから開始してnotebookを再実行すると、前回のnotebookセッション中に作成したファイル`myfile.txt`は失われます。 "
  },
  {
   "cell_type": "code",
   "id": "f6addccb-a5a0-47eb-a342-e0439f903868",
   "metadata": {
    "language": "python",
    "name": "temp_file_py4"
   },
   "outputs": [],
   "source": "import os\nos.listdir()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0c5b674f-239b-4dcc-aaa8-443f0d9313c7",
   "metadata": {
    "name": "save_file_md",
    "collapsed": false
   },
   "source": "## 永続ファイルの操作\n\nセッションに戻ったときに再度アクセスできる永続的な場所にファイルを保存したい場合はどうでしょうか？例えば、モデルを訓練して後で使用するためにモデルを保存したい場合や、分析結果を保存したい場合があります。notebookセッション中に作成されたファイルはデフォルトで一時的なものなので、永続的なSnowflake stageにファイルを移動してファイルを永続的に保存する方法を説明します。\n\nまず、`PERMANENT_STAGE`という名前のstageを作成しましょう："
  },
  {
   "cell_type": "code",
   "id": "33637d1e-e3e9-4959-867a-2850c02024b1",
   "metadata": {
    "language": "sql",
    "name": "save_file_sql1"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE PERMANENT_STAGE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "43f662da-efdb-4c9b-a02b-cd1360b730b0",
   "metadata": {
    "name": "save_file_md2",
    "collapsed": false
   },
   "source": "では、再び一時的なlocal stageに`myfile.txt`を書き込みましょう"
  },
  {
   "cell_type": "code",
   "id": "7b7e46a0-a274-4290-9da4-0177154dd10c",
   "metadata": {
    "language": "python",
    "name": "save_file_py1"
   },
   "outputs": [],
   "source": "with open(\"myfile.txt\",'w') as f:\n    f.write(\"abc\")\nf.close()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d394d6a0-fe88-40fa-9bb7-9e9e79f7bc3c",
   "metadata": {
    "name": "save_file_md3",
    "collapsed": false
   },
   "source": "では、Snowparkを使用して作成したローカルファイルをstageの場所にアップロードしましょう。Notebooksでは、`get_active_session`メソッドを使用して[session](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.Session#snowflake.snowpark.Session)コンテキスト変数を取得し、以下のようにSnowparkを操作できます："
  },
  {
   "cell_type": "code",
   "id": "e4f8c420-aa73-43c3-861f-52fc27483d14",
   "metadata": {
    "language": "python",
    "name": "save_file_py2"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05a6bc0f-f225-411a-ac8b-0a4782939c9a",
   "metadata": {
    "name": "save_file_md4",
    "collapsed": false
   },
   "source": "Snowparkの[session.file.put](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.FileOperation.put)コマンドを使用して、`myfile.txt`をstageの場所`@PERMANENT_STAGE`に移動しましょう"
  },
  {
   "cell_type": "code",
   "id": "9e58d66f-bd0a-498f-9661-b561ebc9a7e9",
   "metadata": {
    "language": "python",
    "name": "save_file_py3"
   },
   "outputs": [],
   "source": "put_result = session.file.put(\"myfile.txt\",\"@PERMANENT_STAGE\", auto_compress= False)\nput_result[0].status",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "851e2048-2dd3-44e9-8322-323644d47c75",
   "metadata": {
    "name": "save_file_md5",
    "collapsed": false
   },
   "source": "ファイルが永続stageにアップロードされました。 "
  },
  {
   "cell_type": "code",
   "id": "83e60834-b1b6-4c8c-b9d0-be4034edf698",
   "metadata": {
    "language": "sql",
    "name": "save_file_sql2"
   },
   "outputs": [],
   "source": "LS @PERMANENT_STAGE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd0de5cb-eba7-4da5-a7e0-9d893134bc56",
   "metadata": {
    "name": "save_file_md6",
    "collapsed": false
   },
   "source": "notebookセッションを切断しても、ファイルが永続stageに残存していることが確認できます。"
  },
  {
   "cell_type": "code",
   "id": "17feda8b-e2ed-4073-b362-a89dc5c64f32",
   "metadata": {
    "language": "sql",
    "name": "save_file_sql3"
   },
   "outputs": [],
   "source": "LS @PERMANENT_STAGE;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45f10192-9930-4453-be84-5c9f12d66c30",
   "metadata": {
    "language": "python",
    "name": "save_file_py4"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nf = session.file.get_stream(\"@PERMANENT_STAGE/myfile.txt\")\nprint(f.readline())\nf.close()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "102483f9-4df7-4580-ad68-6d5368d3c62d",
   "metadata": {
    "name": "save_file_md7",
    "collapsed": false
   },
   "source": "また、読み取る前にファイルをローカルにダウンロードしたい場合は、[session.file.get](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.FileOperation.get)コマンドを使用できます： "
  },
  {
   "cell_type": "code",
   "id": "15287dfa-c2fe-4b70-9ad3-908ab09dd7e3",
   "metadata": {
    "language": "python",
    "name": "save_file_py5"
   },
   "outputs": [],
   "source": "# Download the file from stage to current local path\nget_status = session.file.get(\"@PERMANENT_STAGE/myfile.txt\",\"./\")\nget_status[0].status",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ab5f983-8969-4901-85ee-51d1a47ba4a5",
   "metadata": {
    "language": "python",
    "name": "save_file_py6"
   },
   "outputs": [],
   "source": "import os\nos.listdir()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60c35444-4894-43d3-8cda-ae060a6f8736",
   "metadata": {
    "name": "save_stage_md1",
    "collapsed": false
   },
   "source": "## ボーナス: stageからのデータファイルの操作\n\nstageは、Snowflakeに読み込まれる前にデータファイルを保存する一般的な場所です。前のセクションでは、Snowflake stageに汎用ファイルを読み書きする方法を見ました。ここでは、stageに保存されたテーブル形式のデータファイルを操作する一般的な例をいくつか紹介します。\n"
  },
  {
   "cell_type": "code",
   "id": "95faa3a7-d46f-4d80-92c2-d71c5c83f142",
   "metadata": {
    "language": "python",
    "name": "save_stage_py1"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ac58b10d-e2b6-4e2b-8bd3-5b6aefcbc0ae",
   "metadata": {
    "name": "save_stage_md2",
    "collapsed": false
   },
   "source": "異なる日における様々なスキーリゾート地での降雪量を記録したサンプルデータセットがあります。"
  },
  {
   "cell_type": "code",
   "id": "3f4dde6e-c578-4420-a9e5-a8ee42823236",
   "metadata": {
    "language": "python",
    "name": "save_stage_py2"
   },
   "outputs": [],
   "source": "# Create a Snowpark DataFrame with sample data\ndf = session.create_dataframe([[1, 'Big Bear', 8],[2, 'Big Bear', 10],[3, 'Big Bear', 5],\n                               [1, 'Tahoe', 3],[2, 'Tahoe', 20],[3, 'Tahoe', 13]], \n                              schema=[\"DAY\", \"LOCATION\", \"SNOWFALL\"])\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e06961a5-dd15-4710-8f32-5d733428b129",
   "metadata": {
    "name": "save_stage_md3",
    "collapsed": false
   },
   "source": "Snowpark dataframeをstage上のCSVファイルに書き込む方法は次の通りです："
  },
  {
   "cell_type": "code",
   "id": "c50d23a1-7601-447f-85af-35f0c27fd9e5",
   "metadata": {
    "language": "python",
    "name": "save_stage_py3"
   },
   "outputs": [],
   "source": "df.write.copy_into_location(\"@PERMANENT_STAGE/snowfall.csv\",file_format_type=\"csv\",header=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2688a6bc-50de-4c4b-81ab-72881bf362df",
   "metadata": {
    "name": "save_stage_md4",
    "collapsed": false
   },
   "source": "stage上のファイルにアクセスするには、stageの場所からCSVファイルを読み取ってSnowpark dataframeに戻します："
  },
  {
   "cell_type": "code",
   "id": "c3514346-8b19-4fd1-8322-00980dfd451b",
   "metadata": {
    "language": "python",
    "name": "save_stage_py4"
   },
   "outputs": [],
   "source": "df = session.read.options({\"infer_schema\":True}).csv('@PERMANENT_STAGE/snowfall.csv')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1bc3811-5eed-4b0b-b894-f4520d7b6842",
   "metadata": {
    "name": "save_stage_md5",
    "collapsed": false
   },
   "source": "notebooksでデータファイルを操作する方法について詳しく学ぶには、[外部S3 stageからCSVファイルを操作する方法](https://github.com/Snowflake-Labs/snowflake-demo-notebooks/blob/main/Load%20CSV%20from%20S3/Load%20CSV%20from%20S3.ipynb)と[パブリックエンドポイントからSnowflakeテーブルにデータを読み込む方法](https://github.com/Snowflake-Labs/snowflake-demo-notebooks/blob/main/Ingest%20Public%20JSON/Ingest%20Public%20JSON.ipynb)のチュートリアルをご確認ください。 "
  },
  {
   "cell_type": "code",
   "id": "d8599195-2162-4681-98cd-deda05fe44c5",
   "metadata": {
    "language": "sql",
    "name": "save_stage_sql1"
   },
   "outputs": [],
   "source": "-- Teardown stage created as part of this tutorial\nDROP STAGE PERMANENT_STAGE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ed257c6-b552-4e6d-83c0-61a750047d81",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "### まとめ\n\nこのチュートリアルでは、notebookからローカルファイルを永続的なSnowflake stageにアップロードして、notebookセッション間で結果を永続化する方法を紹介しました。Snowparkのファイル操作コマンド（例：[file.get](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.FileOperation.get)、[file.put](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.FileOperation.put)）を使用して、ローカルファイルパスとstageの場所間でファイルを移動しました。Snowparkでファイルを操作することについての詳細は[こちら](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/io)で学ぶことができます。"
  },
  {
   "cell_type": "markdown",
   "id": "c0aa866e-7fd4-449a-a0b4-51e76b03f751",
   "metadata": {
    "collapsed": false,
    "name": "nextsteps_md"
   },
   "source": [
    "## ノートブックの探求を続けましょう！🧭\n",
    "\n",
    "詳細については、[サンプルノートブックギャラリー](https://github.com/Snowflake-Labs/notebook-demo)と[ドキュメント](https://docs.snowflake.com/LIMITEDACCESS/snowsight-notebooks/ui-snowsight-notebooks-about)をご確認ください！"
   ]
  }
 ]
}